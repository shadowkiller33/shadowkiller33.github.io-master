
<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>Lingfeng Shen</title>

    <meta name="author" content="Lingfeng Shen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
<script type="text/javascript" src="jquery-1.12.4.min.js"></script></head>

<body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.7%;width:75%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Lingfeng Shen</name>
                                    </p>
                                    <p>
                                        My name is Lingfeng Shen(沈凌峰), a first-year master student at Department of Computer Science, Johns Hopkins University, advised by Prof. <a href="https://danielkhashabi.com/" target="_blank">Daniel Khashabi</a>, and Prof. <a href="https://www.cs.jhu.edu/~phi/" target="_blank">Philipp Koehn</a>.
                                        Before that, I received my B.S. degree (Mathematics) from China Agricultural University. My current research interests include:
                                    </p>
                                    <p>
                                        <li class="paper"> Understanding the emergent behaviors of foundation models (e.g., In-context learning): <a href="https://arxiv.org/abs/2305.10713" target="_blank">[1]</a>, <a href="https://arxiv.org/abs/2310.08540" target="_blank">[7]</a>
                                        </li>
                                        <li class="paper"> Algorithmic design in building foundation models: <a href="https://arxiv.org/abs/2309.16155v1" target="_blank">[2]</a>
                                        </li>
                                        <li class="paper"> Security and robustness of foundation models: <a href="https://arxiv.org/abs/2309.16155v1" target="_blank">[2]</a>, <a href="https://arxiv.org/abs/2310.03991" target="_blank">[8]</a>
                                        </li>
                                    </p>
                                    <p>
                                        I used to be interested in adversarial robustness <a href="https://arxiv.org/abs/2302.02023" target="_blank">[3]</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21380" target="_blank">[4]</a>,
                                        backdoor robustness <a href="https://arxiv.org/abs/2201.02993" target="_blank">[5]</a>, and evaluation <a href="https://arxiv.org/abs/2201.02993" target="_blank">[5]</a>, <a href="https://arxiv.org/abs/2202.08479" target="_blank">[6]</a>
                                    </p>
                                    <p>
                                        Email: lshen30[at]jhu.edu
                                    </p>
                                    <p style="text-align:left">
                                        <a href="https://github.com/shadowkiller33" target="_blank">
                                        Github</a> &nbsp;&nbsp;/&nbsp;&nbsp;
                                        <a href="https://scholar.google.com/citations?user=PoSTdLAAAAAJ&hl=en" target="_blank">
                                        Google Scholar</a> &nbsp;&nbsp;/&nbsp;&nbsp; 
                                        <a href="https://twitter.com/Lingfeng_nlp" target="_blank">
                                        Twitter</a> &nbsp;&nbsp;/&nbsp;&nbsp;
                                        <a href="https://www.linkedin.com/in/lingfeng-shen-674106251/" target="_blank">
                                        LinkedIn</a> &nbsp;&nbsp;&nbsp;&nbsp;
                                    </p>
                                </td>
                                <td style="padding:2%;width:40%;max-width:40%">
                                    <a><img style="width:100%;max-width:100%" alt="profile photo" src="ww.jpg" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Publications</heading> (* equal contribution)
                                    <p>
                                        <a href="https://arxiv.org/abs/2310.08540" target="_blank"><papertitle>Do pretrained Transformers Really Learn In-context by Gradient Descent?</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>*, Aayush Mishra*, Daniel Khashabi
                                        <br>
                                        <em>Preprint 2023</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2310.08540" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/shadowkiller33/in-context_learning" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2310.03991" target="_blank"><papertitle>SEMStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation</papertitle></a>
                                        <br>
                                        Abe Bohan Hou, Jingyu Zhang, Tianxing He ,Yichen Wang, Yung-Sung Chuang, Hongwei Wang, <strong>Lingfeng Shen</strong> ,Benjamin Van Durme, Daniel Khashabi, Yulia Tsvetkov
                                        <br>
                                        <em>Preprint 2023</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2310.03991" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2309.16155v1" target="_blank"><papertitle>The Trickle-down Impact of Reward (In-)consistency on RLHF</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>,&nbsp;
                                        Sihao Chen,&nbsp;Linfeng Song, Lifeng Jin, Baolin Peng, Haitao Mi, Daniel Khashabi, Dong Yu
                                        <br>
                                        <em>Preprint 2023</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2309.16155v1" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/shadowkiller33/Contrast-Instruction" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2305.10713" target="_blank"><papertitle>Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen*</strong>,&nbsp;
                                        Steven Tan*,&nbsp;Boyuan Zheng, Daniel Khashabi
                                        <br>
                                        <em>EMNLP 2023 findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2305.10713" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/shadowkiller33/flatness" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/pdf/2306.02247.pdf" target="_blank"><papertitle>Sen2Pro: A Probabilistic Perspective to Sentence Embedding from Pre-trained Language Model</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>,&nbsp;Haiyun Jiang, Lemao Liu, Shuming Shi
                                        <br>
                                        <em>ACL 2023, Rep4NLP workshop</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/pdf/2306.02247.pdf" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/shadowkiller33/Sen2Pro" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2302.02023" target="_blank"><papertitle>TextShield: Beyond Successfully Detecting Adversarial Sentences in Text Classification</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>,&nbsp;Ze Zhang, Haiyun Jiang, Ying Chen
                                        <br>
                                        <em>ICLR2023</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2302.02023" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2202.08479" target="_blank"><papertitle>On the Evaluation Metrics for Paraphrase Generation</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>,&nbsp;Lemao Liu, Haiyun Jiang, Shuming Shi
                                        <br>
                                        <em>EMNLP2022</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2202.08479" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/shadowkiller33/ParaScore" target="_blank">code</a>
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21380" target="_blank"><papertitle>KATG: Keyword-bias-aware Adversarial Text Generation for Text Classification</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>, Shoushan Li, Ying Chen
                                        <br>
                                        <em>AAAI2022 (Oral)</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21380" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790504.pdf" target="_blank"><papertitle>DRCNet: Dynamic Image Restoration Contrastive Network</papertitle></a>
                                        <br>
                                        Fei Li*, <strong>Lingfeng Shen*</strong>, Yang Mi, Zhenbo Li
                                        <br>
                                        <em>ECCV2022</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790504.pdf" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/leefly072/DRCNet" target="_blank">code</a>
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2201.02993" target="_blank"><papertitle>Rethink stealthy backdoor attacks in natural language processing</papertitle></a>
                                        <br>
                                        <strong>Lingfeng Shen</strong>,&nbsp;Haiyun Jiang, Lemao Liu, Shuming Shi
                                        <br>
                                        <em>Preprint 2022</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2201.02993" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
<!--                                    <p>                                   <p>-->
<!--                                        <a href="https://ieeexplore.ieee.org/abstract/document/9377758" target="_blank"><papertitle>Forecasting People's Action via Social Media Data</papertitle></a>-->
<!--                                        <br>-->
<!--                                        <strong>Lingfeng Shen</strong>,&nbsp;Haiyun Jiang, Lemao Liu, Shuming Shi-->
<!--                                        <br>-->
<!--                                        <em>IEEE conference on Big Data (2021)</em>&nbsp;&nbsp;-->
<!--                                        <br>-->
<!--                                        <a href="https://ieeexplore.ieee.org/abstract/document/9377758" target="_blank">paper</a>&nbsp;&nbsp;-->
<!--                                        <br>-->
<!--                                    </p>-->
                                </td>
                            </tr>      
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Miscellaneous</heading>
                                    <p>
                                        <li class="paper"> Motorsports ignite my passion, particularly Formula 1. I'm ardently devoted to the <a href="https://www.mercedesamgf1.com/" target="_blank">Mercedes-AMG Petronas F1 Team</a>.
                                        </li>
                                    </p>
                                    <p>
                                        <li class="paper">
                                            The NBA also has a special place in my heart; I rallied behind the Houston Rockets from
                                            Yao Ming's debut until James Harden was traded.
                                        </li>
                                    </p>
                                    <p>
                                        <li class="paper">
                                            Off the screen, you'll often find me karting with friends or clocking laps on the race track or playing video games.
                                        </li>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Services</heading>
                                    <p>
                                        <li class="paper"> Reviewers: ICLR2024, NeurIPS 2023, ICML 2023, ACL 2023, AAAI 2023/2024, AAAI2022, EMNLP 2022/2023, ARR 2022/2023.
                                        </li>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <br>
                                    <div>
                                        <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=IU__z9hnX1_6xF6PicstVR9foICWQedmUuHhQKX6SVw&cl=ffffff&w=a"></script>
                                    </div>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <p font-size:small;="">
                                        <br>
                                        <br>
                                        </p><div style="float:left;">
                                            Updated at July 2023
                                        </div>
                                        <div style="float:right;">
                                            Thanks <a href="https://jonbarron.info/">Jon Barron</a> for this amazing work
                                        </div>
                                        <br>
                                        <br>        
                                    <p></p>                           
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </tbody></table>

<div class="jvectormap-tip"></div></body></html>
